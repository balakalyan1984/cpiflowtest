apiVersion: ai.sap.com/v1alpha1
kind: ServingTemplate
metadata:
  name: cpiflow-serving-pipeline
  annotations:
    scenarios.ai.sap.com/name: "CPIFLOW Optimizer PRO"
    scenarios.ai.sap.com/description: "FastAPI on KServe"
    executables.ai.sap.com/name: "cpiflow-model-serving"              # REQUIRED
    executables.ai.sap.com/description: "All-in-one CPI classifier API"
    artifacts.ai.sap.com/cpiflowmodel.kind: "model"                   # declare input artifact kind
  labels:
    scenarios.ai.sap.com/id: "cpiflow-optimizer-pro"
    ai.sap.com/version: "6.6"                                         # bump to force new Revision
spec:
  inputs:
    artifacts:
      - name: cpiflowmodel
  template:
    apiVersion: serving.kserve.io/v1beta1
    kind: InferenceService
    metadata:
      name: cpiflow-serving
      annotations:
        autoscaling.knative.dev/metric: concurrency
        autoscaling.knative.dev/target: "1"
        autoscaling.knative.dev/targetBurstCapacity: "0"
      labels:
        ai.sap.com/resourcePlan: starter
    spec:
      predictor:
        minReplicas: 1
        maxReplicas: 2
        containers:
          - name: kserve-container
            image: docker.io/balakalyandocker/cpiflow-serve:py312-v1
            command: ["/bin/sh","-lc"]
            args:
              - |
                set -e
                export MODEL_MOUNT_DIR="${MODEL_MOUNT_DIR:-/mnt/models}"
                # optional: auto-descend wrappers up to 3 levels
                for i in 1 2 3; do
                  if [ -d "$MODEL_MOUNT_DIR" ]; then
                    c="$(ls -1 "$MODEL_MOUNT_DIR" | wc -l | tr -d ' ')"
                    if [ "$c" = "1" ]; then
                      o="$(ls -1 "$MODEL_MOUNT_DIR")"
                      [ -d "$MODEL_MOUNT_DIR/$o" ] && MODEL_MOUNT_DIR="$MODEL_MOUNT_DIR/$o" && continue
                    fi
                  fi
                  break
                done
                export MODEL_PATH="$MODEL_MOUNT_DIR/model.pkl"
                exec uvicorn --app-dir /app/src serve_cpiflow_kserve:app --host 0.0.0.0 --port ${PORT:-8080}
            env:
              - name: STORAGE_URI
                value: "{{inputs.artifacts.cpiflowmodel}}"
              - name: MODEL_MOUNT_DIR
                value: "/mnt/models"
            ports:
              - name: http1
                containerPort: 8080
            readinessProbe:
              httpGet:
                path: /health
                port: 8080
              initialDelaySeconds: 2
              periodSeconds: 5
            resources:
              requests:
                cpu: "100m"
                memory: "256Mi"
              limits:
                cpu: "1"
                memory: "1Gi"
