# cpiflow-serving-pipeline.yaml
apiVersion: ai.sap.com/v1alpha1
kind: ServingTemplate
metadata:
  name: cpiflow-serving-pipeline
  annotations:
    scenarios.ai.sap.com/name: "CPIFLOW Optimizer PRO"
    scenarios.ai.sap.com/description: "Serving CPIFLOW classifier via KServe"
    executables.ai.sap.com/name: "cpiflow-model-serving"          # dns-label; no spaces
    executables.ai.sap.com/description: "FastAPI server for CPIFLOW classifier"
    artifacts.ai.sap.com/cpiflowmodel.kind: "model"
  labels:
    scenarios.ai.sap.com/id: "cpiflow-optimizer-pro"
    ai.sap.com/version: "9.1"                                      # bump to force new Revision
spec:
  inputs:
    artifacts:
      - name: cpiflowmodel
  template:
    apiVersion: "serving.kserve.io/v1beta1"
    metadata:
      annotations: |
        autoscaling.knative.dev/metric: concurrency
        autoscaling.knative.dev/target: 1
        autoscaling.knative.dev/targetBurstCapacity: 0
      labels: |
        ai.sap.com/resourcePlan: starter
    spec: |
      predictor:
        imagePullSecrets:
          - name: milton-credentials
        minReplicas: 1
        maxReplicas: 2
        containers:
        - name: kserve-container
          image: docker.io/balakalyandocker/cpiflow-serve:py312-v1
          imagePullPolicy: Always
          ports:
            - name: http1
              containerPort: 8080
              protocol: TCP
          command: ["/bin/sh","-lc"]
          args: |
            set -e
            M="${MODEL_MOUNT_DIR:-/mnt/models}"

            echo "== DEBUG: mounted at $M =="
            ls -la "$M" || true

            # Find model.pkl under wrapper dirs and symlink to /mnt/models/model.pkl
            FOUND="$(python - <<'PY'
import os
root=os.environ.get("MODEL_MOUNT_DIR","/mnt/models")
for base,_,files in os.walk(root):
    if "model.pkl" in files:
        print(os.path.join(base,"model.pkl")); break
PY
)"
            [ -n "$FOUND" ] || { echo "ERROR: model.pkl not found under $M"; exit 2; }
            echo "Found model at: $FOUND"
            ln -sf "$FOUND" "$M/model.pkl"
            ls -la "$M"

            exec uvicorn --app-dir /app/src serve_cpiflow_kserve:app --host 0.0.0.0 --port ${PORT:-8080}
          env:
            - name: STORAGE_URI
              value: "{{inputs.artifacts.cpiflowmodel}}"    # AI Core mounts this under /mnt/models
            - name: MODEL_MOUNT_DIR
              value: "/mnt/models"
          readinessProbe:
            httpGet:
              path: /health
              port: 8080
            initialDelaySeconds: 2
            periodSeconds: 5
          livenessProbe:
            httpGet:
              path: /health
              port: 8080
            initialDelaySeconds: 10
            periodSeconds: 10
          resources:
            requests:
              cpu: "100m"
              memory: "256Mi"
            limits:
              cpu: "1"
              memory: "1Gi"
