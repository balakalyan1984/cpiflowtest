apiVersion: ai.sap.com/v1alpha1
kind: ServingTemplate
metadata:
  name: cpiflow-serving-pipeline
  annotations:
    scenarios.ai.sap.com/name: "CPIFLOW Optimizer"
    scenarios.ai.sap.com/description: "Serving via FastAPI on KServe"
    executables.ai.sap.com/name: "cpiflow-model-serving"
    executables.ai.sap.com/description: "FastAPI server for CPI classifier"
    artifacts.ai.sap.com/cpiflowmodel.kind: "model"
  labels:
    scenarios.ai.sap.com/id: "cpiflow-optimizer"
    ai.sap.com/version: "4.0"

spec:
  inputs:
    artifacts:
      - name: cpiflowmodel

  # KServe InferenceService embedded as YAML string
  template: |
    apiVersion: serving.kserve.io/v1beta1
    kind: InferenceService
    metadata:
      name: cpiflow-serving
      annotations:
        autoscaling.knative.dev/metric: concurrency
        autoscaling.knative.dev/target: "1"
        autoscaling.knative.dev/targetBurstCapacity: "0"
      labels:
        ai.sap.com/resourcePlan: starter
    spec:
      predictor:
        imagePullSecrets:
          - name: milton-credentials
        minReplicas: 1
        maxReplicas: 3
        containers:
          - name: kserve-container
            image: docker.io/balakalyandocker/cpiflow-serve:py312-v1
            command: ["/bin/sh", "-c"]
            args:
              - >
                set -e;
                uvicorn serve_cpiflow_kserve:app --host 0.0.0.0 --port ${PORT:-8080}
            env:
              - name: STORAGE_URI
                value: "{{inputs.artifacts.cpiflowmodel}}"
            ports:
              - name: http1
                containerPort: 8080
            resources:
              requests:
                cpu: "250m"
                memory: "512Mi"
              limits:
                cpu: "1"
                memory: "1Gi"
