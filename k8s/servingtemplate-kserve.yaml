apiVersion: ai.sap.com/v1alpha1
kind: ServingTemplate
metadata:
  name: cpiflow-serving-pipeline
  annotations:
    scenarios.ai.sap.com/name: "CPI Logs Classifier"
    scenarios.ai.sap.com/description: "Serving CPI Logs classifier via KServe"
    executables.ai.sap.com/name: "cpimodelserving"
    executables.ai.sap.com/description: "FastAPI server for CPI classifier"
    artifacts.ai.sap.com/cpimodel.kind: "model"
  labels:
    scenarios.ai.sap.com/id: "cpi-logs-classifier"
    ai.sap.com/version: "4.0"

spec:
  inputs:
    artifacts:
      - name: cpimodel

  template:
    apiVersion: serving.kserve.io/v1beta1
    kind: InferenceService
    metadata:
      name: cpi-serving
      annotations:
        autoscaling.knative.dev/metric: concurrency
        autoscaling.knative.dev/target: "1"
        autoscaling.knative.dev/targetBurstCapacity: "0"
      labels:
        ai.sap.com/resourcePlan: starter
    spec:
      predictor:
        imagePullSecrets:
          - name: <milton-credentials>
        minReplicas: 1
        maxReplicas: 3
        containers:
          - name: kserve-container
            image: docker.io/<balakalyandocker>/cpilog-serve:py312-v1
            command: ["/bin/sh", "-c"]
            args:
              - >
                set -e;
                uvicorn --app-dir /app/src serve_cpi_kserve:app
                --host 0.0.0.0 --port ${PORT:-8080}
            env:
              - name: STORAGE_URI
                value: "{{inputs.artifacts.cpimodel}}"
            ports:
              - name: http1
                containerPort: 8080
            resources:
              requests:
                cpu: "250m"
                memory: "512Mi"
              limits:
                cpu: "1"
                memory: "1Gi"

